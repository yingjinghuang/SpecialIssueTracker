name: Update Special Issues Data

on:
  schedule:
    # Run every day at 8:00 AM UTC (4:00 PM Beijing Time)
    - cron: '0 8 * * *'
  
  workflow_dispatch:  # Allow manual trigger
  
  push:
    branches:
      - main
    paths:
      - 'scraper.py'
      - 'requirements.txt'
      - 'manual_issues.yaml'
      - 'update_manual.py'

jobs:
  update-data:
    runs-on: ubuntu-latest
    
    permissions:
      contents: write
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Install Playwright browsers
        run: |
          playwright install --with-deps chromium
      
      - name: Run Playwright scraper
        run: |
          python scraper.py
          
      - name: Fallback to manual configuration if scraper produces no data
        run: |
          # Check if scraper produced valid data
          ISSUE_COUNT=$(python -c "import json; data=json.load(open('data/special_issues.json')); print(sum(len(j['special_issues']) for j in data['journals']))")
          if [ "$ISSUE_COUNT" -eq "0" ]; then
            echo "⚠️ Scraper found no issues, using manual configuration as fallback"
            python update_manual.py
          else
            echo "✓ Scraper found $ISSUE_COUNT issues"
          fi
      
      - name: Commit and push if changed
        run: |
          git config --global user.name 'GitHub Action'
          git config --global user.email 'action@github.com'
          git add data/special_issues.json
          git diff --quiet && git diff --staged --quiet || (git commit -m "Update special issues data [skip ci]" && git push)