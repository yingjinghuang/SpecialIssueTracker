# ğŸ“˜ ä½¿ç”¨æŒ‡å— | User Guide

## ğŸ¤– å®Œå…¨è‡ªåŠ¨åŒ–æ–¹æ¡ˆ

æœ¬é¡¹ç›®ä½¿ç”¨ **Playwright** å®ç°å®Œå…¨è‡ªåŠ¨åŒ–çš„æœŸåˆŠç‰¹åˆŠè¿½è¸ªï¼Œæ— éœ€æ‰‹åŠ¨ç»´æŠ¤ï¼

## ğŸ¯ å·¥ä½œåŸç†

### æŠ€æœ¯æ ˆ
- **Playwright** - Microsoft å¼€å‘çš„æµè§ˆå™¨è‡ªåŠ¨åŒ–å·¥å…·
- **GitHub Actions** - è‡ªåŠ¨åŒ–è¿è¡Œçˆ¬è™«
- **GitHub Pages** - æ‰˜ç®¡ç½‘ç«™

### è‡ªåŠ¨åŒ–æµç¨‹

```
æ¯å¤© 8:00 UTC (16:00 åŒ—äº¬æ—¶é—´)
    â†“
GitHub Actions è§¦å‘
    â†“
å¯åŠ¨ Playwright æ— å¤´æµè§ˆå™¨
    â†“
è®¿é—®æœŸåˆŠç‰¹åˆŠé¡µé¢
    â†“
æå–ç‰¹åˆŠä¿¡æ¯
    â†“
ä¿å­˜ä¸º JSON
    â†“
è‡ªåŠ¨æäº¤åˆ°ä»“åº“
    â†“
GitHub Pages è‡ªåŠ¨æ›´æ–°
```

## ğŸ“ æ·»åŠ æ–°æœŸåˆŠ

### 1. ç¼–è¾‘ scraper.py

æ‰¾åˆ° `self.journals` åˆ—è¡¨å¹¶æ·»åŠ æ–°æœŸåˆŠï¼š

```python
self.journals = [
    # ... ç°æœ‰æœŸåˆŠ ...
    
    # æ·»åŠ ä½ çš„æ–°æœŸåˆŠ
    {
        'name': 'æœŸåˆŠå®Œæ•´åç§°',  # ä¾‹å¦‚ï¼š'Nature Communications'
        'url': 'ç‰¹åˆŠé¡µé¢URL',     # ä¸»URL
        'backup_url': 'å¤‡ç”¨URL'   # å¤‡ç”¨URLï¼ˆå¯é€‰ï¼‰
    }
]
```

### 2. æäº¤æ›´æ”¹

```bash
git add scraper.py
git commit -m "Add new journal: [æœŸåˆŠåç§°]"
git push
```

### 3. è‡ªåŠ¨è¿è¡Œ

GitHub Actions ä¼šè‡ªåŠ¨ï¼š
- æ£€æµ‹åˆ°æ–‡ä»¶å˜æ›´
- è¿è¡Œçˆ¬è™«æµ‹è¯•æ–°æœŸåˆŠ
- æ›´æ–°æ•°æ®

## ğŸ”§ è°ƒæ•´çˆ¬è™«è¡Œä¸º

### ä¿®æ”¹çˆ¬å–é¢‘ç‡

ç¼–è¾‘ `.github/workflows/update-data.yml`:

```yaml
schedule:
  # é»˜è®¤ï¼šæ¯å¤©ä¸€æ¬¡
  - cron: '0 8 * * *'
  
  # æ¯12å°æ—¶ä¸€æ¬¡
  # - cron: '0 */12 * * *'
  
  # æ¯å‘¨ä¸€æ¬¡ï¼ˆå‘¨ä¸€8ç‚¹ï¼‰
  # - cron: '0 8 * * 1'
```

### å¢åŠ ç­‰å¾…æ—¶é—´

å¦‚æœçˆ¬è™«å¤ªå¿«å¯¼è‡´é—®é¢˜ï¼Œå¯ä»¥å¢åŠ å»¶è¿Ÿï¼š

åœ¨ `scraper.py` ä¸­æ‰¾åˆ°ï¼š
```python
await page.wait_for_timeout(2000)  # 2ç§’
```

æ”¹ä¸ºï¼š
```python
await page.wait_for_timeout(5000)  # 5ç§’
```

## ğŸ› æ•…éšœæ’æŸ¥

### é—®é¢˜1ï¼šGitHub Actions å¤±è´¥

**æ£€æŸ¥æ­¥éª¤ï¼š**
1. è¿›å…¥ Actions æ ‡ç­¾
2. ç‚¹å‡»å¤±è´¥çš„è¿è¡Œè®°å½•
3. æŸ¥çœ‹é”™è¯¯æ—¥å¿—

**å¸¸è§åŸå› ï¼š**
- ç½‘ç«™ç»“æ„å˜åŒ–
- ç½‘ç»œè¶…æ—¶
- Playwright æµè§ˆå™¨é—®é¢˜

**è§£å†³æ–¹æ³•ï¼š**
```bash
# æœ¬åœ°æµ‹è¯•çˆ¬è™«
pip install -r requirements.txt
playwright install chromium
python scraper.py
```

### é—®é¢˜2ï¼šçˆ¬ä¸åˆ°æ•°æ®

**å¯èƒ½åŸå› ï¼š**
- ç½‘ç«™æ”¹ç‰ˆ
- é€‰æ‹©å™¨å¤±æ•ˆ
- åçˆ¬è™«æ£€æµ‹

**è°ƒè¯•æ–¹æ³•ï¼š**

1. åœ¨ `scraper.py` ä¸­å¯ç”¨ headful æ¨¡å¼ï¼š
```python
browser = await p.chromium.launch(headless=False)  # æ”¹ä¸º False
```

2. æ·»åŠ è°ƒè¯•æ—¥å¿—ï¼š
```python
print(f"Page title: {await page.title()}")
print(f"URL: {page.url}")
```

3. æˆªå›¾è°ƒè¯•ï¼š
```python
await page.screenshot(path='debug.png')
```

### é—®é¢˜3ï¼šæ•°æ®æ ¼å¼é”™è¯¯

æ£€æŸ¥ `data/special_issues.json` æ ¼å¼ï¼š

```json
{
  "last_updated": "2026-02-08 12:00:00",
  "journals": [
    {
      "name": "æœŸåˆŠåç§°",
      "url": "URL",
      "special_issues": [...]
    }
  ]
}
```

## ğŸ¨ è‡ªå®šä¹‰ç•Œé¢

### ä¿®æ”¹ç½‘ç«™æ ·å¼

ç¼–è¾‘ `index.html` ä¸­çš„ CSSï¼š

```css
/* ä¿®æ”¹ä¸»é¢˜è‰² */
header {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
}

/* ä¿®æ”¹å¡ç‰‡æ ·å¼ */
.issue-card {
    border-radius: 12px;
    box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
}
```

### æ·»åŠ æ–°è¯­è¨€

åœ¨ `index.html` ä¸­ï¼š

```html
<select id="secondLang">
    <!-- æ·»åŠ æ–°è¯­è¨€ -->
    <option value="it">Italiano (Italian)</option>
    <option value="nl">Nederlands (Dutch)</option>
</select>
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### 1. å‡å°‘çˆ¬å–æ—¶é—´

```python
# åœ¨ scraper.py ä¸­
# å‡å°‘ç­‰å¾…æ—¶é—´
await page.goto(url, wait_until='domcontentloaded')  # è€Œä¸æ˜¯ 'networkidle'

# è·³è¿‡å›¾ç‰‡å’ŒCSS
await context.new_page()
await context.route("**/*.{png,jpg,jpeg,css}", lambda route: route.abort())
```

### 2. å¹¶å‘çˆ¬å–å¤šä¸ªæœŸåˆŠ

```python
async def scrape_all_concurrent(self):
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        
        tasks = []
        for journal in self.journals:
            page = await browser.new_page()
            tasks.append(self.scrape_journal(page, journal))
        
        results = await asyncio.gather(*tasks)
        await browser.close()
```

## ğŸŒ å¤šè¯­è¨€ç¿»è¯‘

å½“å‰ä½¿ç”¨ Google Translate APIï¼ˆæµè§ˆå™¨ç«¯ï¼‰ã€‚

å¦‚éœ€æ›´é«˜è´¨é‡ç¿»è¯‘ï¼Œå¯ä»¥é›†æˆï¼š
- DeepL API
- Microsoft Translator
- Google Cloud Translation API

## ğŸ’¡ æœ€ä½³å®è·µ

1. **å®šæœŸæ£€æŸ¥**ï¼šæ¯æœˆæŸ¥çœ‹ä¸€æ¬¡ Actions æ—¥å¿—
2. **å¤‡ä»½æ•°æ®**ï¼šå®šæœŸä¸‹è½½ `special_issues.json`
3. **æµ‹è¯•æœŸåˆŠ**ï¼šæ·»åŠ æ–°æœŸåˆŠåæ‰‹åŠ¨è§¦å‘ä¸€æ¬¡ Actions
4. **å°Šé‡ç½‘ç«™**ï¼šä¸è¦è®¾ç½®è¿‡äºé¢‘ç¹çš„çˆ¬å–
5. **ç‰ˆæœ¬æ§åˆ¶**ï¼šå¯¹çˆ¬è™«é€»è¾‘çš„é‡è¦ä¿®æ”¹åšå¥½æ³¨é‡Š

## ğŸ“ è·å–å¸®åŠ©

- **Bug æŠ¥å‘Š**ï¼šåˆ›å»º GitHub Issue
- **åŠŸèƒ½è¯·æ±‚**ï¼šåˆ›å»º GitHub Discussion
- **ä»£ç è´¡çŒ®**ï¼šæäº¤ Pull Request

---

**Enjoy automated tracking!** ğŸ‰